{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1b63f5-2b84-438d-803f-e996f8a346a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isxzl\\anaconda3\\envs\\autoGPT\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from lightly.data import LightlyDataset, SimCLRCollateFunction, collate\n",
    "from lightly.loss import NTXentLoss\n",
    "from lightly.models import ResNetGenerator\n",
    "from lightly.models.modules.heads import MoCoProjectionHead\n",
    "from lightly.models.utils import (\n",
    "    batch_shuffle,\n",
    "    batch_unshuffle,\n",
    "    deactivate_requires_grad,\n",
    "    update_momentum,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80f7d6f-f39f-4797-bf27-6ad5754aa592",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "batch_size = 512\n",
    "memory_bank_size = 4096\n",
    "seed = 1\n",
    "max_epochs = 1\n",
    "input_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86bc2af-bd90-4801-bf78-c418e856b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = \"../Datasets/cifar10/train/\"\n",
    "path_to_test = \"../Datasets/cifar10/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4740f441-2fe0-42a1-9cf9-d7ec52082e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25212e21-6cb6-45ad-931d-0a132c628699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MoCo v2 uses SimCLR augmentations, additionally, disable blur\n",
    "collate_fn = SimCLRCollateFunction(input_size=input_size, vf_prob=0.5, rr_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bff137f-e615-49b7-b4f4-7e0ebdba5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations typically used to train on cifar-10\n",
    "train_classifier_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.RandomCrop(input_size, padding=4),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=collate.imagenet_normalize[\"mean\"],\n",
    "            std=collate.imagenet_normalize[\"std\"],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# No additional augmentations for the test set\n",
    "test_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((input_size, input_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=collate.imagenet_normalize[\"mean\"],\n",
    "            std=collate.imagenet_normalize[\"std\"],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc1717d-8298-4dbc-9df4-a1536a122468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We use the moco augmentations for training moco\n",
    "dataset_train_moco = LightlyDataset(input_dir=path_to_train)\n",
    "\n",
    "# Since we also train a linear classifier on the pre-trained moco model we\n",
    "# reuse the test augmentations here (MoCo augmentations are very strong and\n",
    "# usually reduce accuracy of models which are not used for contrastive learning.\n",
    "# Our linear layer will be trained using cross entropy loss and labels provided\n",
    "# by the dataset. Therefore we chose light augmentations.)\n",
    "dataset_train_classifier = LightlyDataset(\n",
    "    input_dir=path_to_train, transform=train_classifier_transforms\n",
    ")\n",
    "\n",
    "dataset_test = LightlyDataset(input_dir=path_to_test, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1ce14-17af-4496-bef5-7d86f0c7c140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7bedd94-3865-466c-a63e-364a845aae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train_moco = torch.utils.data.DataLoader(\n",
    "    dataset_train_moco,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "dataloader_train_classifier = torch.utils.data.DataLoader(\n",
    "    dataset_train_classifier,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66314f43-1227-4d38-b431-040d41201baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MocoModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = ResNetGenerator(\"resnet-18\", 1, num_splits=8)\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(resnet.children())[:-1],\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "\n",
    "        # create a moco model based on ResNet\n",
    "        self.projection_head = MoCoProjectionHead(512, 512, 128)\n",
    "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "        deactivate_requires_grad(self.backbone_momentum)\n",
    "        deactivate_requires_grad(self.projection_head_momentum)\n",
    "\n",
    "        # create our loss with the optional memory bank\n",
    "        self.criterion = NTXentLoss(temperature=0.1, memory_bank_size=memory_bank_size)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x_q, x_k), _, _ = batch\n",
    "\n",
    "        # update momentum\n",
    "        update_momentum(self.backbone, self.backbone_momentum, 0.99)\n",
    "        update_momentum(self.projection_head, self.projection_head_momentum, 0.99)\n",
    "\n",
    "        # get queries\n",
    "        q = self.backbone(x_q).flatten(start_dim=1)\n",
    "        q = self.projection_head(q)\n",
    "\n",
    "        # get keys\n",
    "        k, shuffle = batch_shuffle(x_k)\n",
    "        k = self.backbone_momentum(k).flatten(start_dim=1)\n",
    "        k = self.projection_head_momentum(k)\n",
    "        k = batch_unshuffle(k, shuffle)\n",
    "\n",
    "        loss = self.criterion(q, k)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    #def on_train_epoch_end(self):\n",
    "     #   self.custom_histogram_weights()\n",
    "\n",
    "    # We provide a helper method to log weights in tensorboard\n",
    "    # which is useful for debugging.\n",
    "  #  def custom_histogram_weights(self):\n",
    "    #    for name, params in self.named_parameters():\n",
    "    #        self.logger.experiment.add_histogram(name, params, self.current_epoch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=6e-2,\n",
    "            momentum=0.9,\n",
    "            weight_decay=5e-4,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f9f2181-d66e-40cc-a33a-81559ca7fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                     | Type               | Params\n",
      "----------------------------------------------------------------\n",
      "0 | backbone                 | Sequential         | 11.2 M\n",
      "1 | projection_head          | MoCoProjectionHead | 328 K \n",
      "2 | backbone_momentum        | Sequential         | 11.2 M\n",
      "3 | projection_head_momentum | MoCoProjectionHead | 328 K \n",
      "4 | criterion                | NTXentLoss         | 0     \n",
      "----------------------------------------------------------------\n",
      "11.5 M    Trainable params\n",
      "11.5 M    Non-trainable params\n",
      "23.0 M    Total params\n",
      "91.977    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████████████████████████████████████████████████| 97/97 [01:12<00:00,  1.34it/s, v_num=14]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████████████████████████████████████████████████| 97/97 [01:12<00:00,  1.33it/s, v_num=14]\n"
     ]
    }
   ],
   "source": [
    "model = MocoModel()\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\")\n",
    "trainer.fit(model, dataloader_train_moco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5e331-85d0-4266-a65d-4a9984ecfb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | backbone  | Sequential       | 11.2 M\n",
      "1 | fc        | Linear           | 5.1 K \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030475b-c05e-4b32-a410-19b8e8251b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Initialize features and labels as empty numpy arrays\n",
    "X_train = np.array([])\n",
    "y_train = np.array([])\n",
    "\n",
    "# Wrap your dataloader with tqdm for a progress bar\n",
    "for image, target, fname in tqdm(dataloader_train_classifier):\n",
    "    with torch.no_grad():\n",
    "        # Forward pass to extract features\n",
    "        # Note: You might need to modify this depending on the output of your SimCLR model\n",
    "        feature = model(image.to(device)).cpu().numpy().flatten()\n",
    "        target = target.cpu().numpy().flatten()\n",
    "\n",
    "        # If features and labels are empty, assign the first feature and label\n",
    "        # Else, stack the new feature and label as a new row\n",
    "\n",
    "        if X_train.size == 0 and y_train.size == 0:\n",
    "            X_train = feature\n",
    "            y_train = target\n",
    "        else:\n",
    "            X_train = np.vstack((X_train, feature))\n",
    "            y_train = np.hstack((y_train, target))\n",
    "            \n",
    "# Train the SVM classifier\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize features and labels as empty numpy arrays\n",
    "X_test = np.array([])\n",
    "y_test = np.array([])\n",
    "\n",
    "for image, target, fname in tqdm(dataloader_test):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        feature = model(image.to(device)).cpu().numpy().flatten()\n",
    "        target = target.cpu().numpy().flatten()\n",
    "\n",
    "    if X_test.size == 0 and y_test.size == 0:\n",
    "        X_test = feature\n",
    "        y_test = target\n",
    "    else:\n",
    "        X_test = np.vstack((X_test, feature))\n",
    "        y_test = np.hstack((y_test, target))\n",
    "\n",
    "# Predict labels for test data\n",
    "X_test_predicted = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, X_test_predicted)\n",
    "\n",
    "print(f\"Model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbda431-5f7e-48dc-86e2-8e1f89997336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabbd621-b36b-4f10-9dc0-e70415f72190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
