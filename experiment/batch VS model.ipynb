{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4533ee81-d579-4867-b15b-aa7f3f8f385f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment Introduction\n",
    "\n",
    "Background, \n",
    "In order to do ablation experiment, we have diffculty like\n",
    "1. most of them are same, we have to repeat many times.\n",
    "2. too many model, config, code hard to manage and save. too messy\n",
    "\n",
    "\n",
    "For all kind of SSL training workflow, we have to define the hyperparameters includes 4 aspect,\n",
    "Dataset\n",
    "Model\n",
    "Training\n",
    "Saving COnfig\n",
    "\n",
    "\n",
    "\n",
    "How to Use this Experiment?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5e60f-6c7d-47b6-8b30-5ad2e6c94b09",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71222088-d62f-40fc-b935-f9c8ee99a579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import config\n",
    "import sys \n",
    "sys.path.append(\"C:/Users/isxzl/OneDrive/Code/VICReg-BarlowTwins-Ablation-Study/autoSSL\")\n",
    "sys.path.append(\"C:/Users/isxzl/OneDrive/Code/VICReg-BarlowTwins-Ablation-Study/\")\n",
    "\n",
    "import yaml\n",
    "from torchvision.transforms import RandomRotation,GaussianBlur,ColorJitter\n",
    "from autoSSL.evaluate import eval_KNN,eval_linear,eval_KNNplot,pipe_collate\n",
    "from autoSSL.models import BarlowTwins, BYOL, MoCo, SimCLR, SimSiam, VICReg ,pipe_model \n",
    "from autoSSL.utils import embedding_feature,ck_callback,dict2transformer,join_dir,ContinuousCSVLogger  \n",
    "from autoSSL.data import PipeDataset\n",
    "from autoSSL.train import Trainer\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eba85e-c2d4-4ed3-a276-2b03ff82f764",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Global Baseline Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0e5479-43a3-4b63-b9e2-b8ce70103290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML file\n",
    "with open('global.yaml', 'r') as file:\n",
    "    global_config = yaml.safe_load(file)\n",
    "\n",
    "# Write your experiment notebook name here\n",
    "global_config[\"experiment\"]=\"batch VS model\"     \n",
    "    \n",
    "# Define global view function\n",
    "global_SSL_augmentation = {\n",
    "    'RandomResizedCrop': {'size': (global_config[\"input_size\"], global_config[\"input_size\"])},\n",
    "    'RandomApply':{'transforms':[RandomRotation(degrees=90)], 'p':0.8},\n",
    "    'RandomHorizontalFlip': {'p': 0.5},\n",
    "    'RandomVerticalFlip':  {'p':0.5},\n",
    "    'RandomApply':{'transforms': [ColorJitter(brightness=0.04,contrast=0.04,saturation=0.02,hue=0.01)], 'p':0.8},\n",
    "    'RandomGrayscale' :{'p':0.2},\n",
    "    'RandomSolarize':{'threshold':128, 'p':0.1},\n",
    "    'RandomApply':{'transforms':[GaussianBlur(kernel_size=3,sigma=(0.2, 2))],'p':0.8},\n",
    "    'ToTensor': {},\n",
    "    'Normalize': {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f84c3-1365-48e8-8ac9-6fdeb5c7a5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a869f3e-3e94-4d05-bec5-6fdd31695b58",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e6970-4604-485e-bd37-60383de96b81",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1352c0-9e27-470a-919d-af85ba9365b5",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"batch_32\"\n",
    "config[\"batch\"]=32\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb66c1a-89fa-4ce2-9f35-92ba04726170",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"batch_64\"\n",
    "config[\"batch\"]=64\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67682be1-2079-464a-97e5-26c474f5bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"batch_128\"\n",
    "config[\"batch\"]=128\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24b2f5-fdec-471c-a610-7d23c7006da4",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"batch_256\"\n",
    "config[\"batch\"]=256\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a536029d-1a2d-4f86-8513-4afd55858850",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"batch_512\"\n",
    "config[\"batch\"]=512\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe001b96-2c3a-478f-89ee-160536ddc097",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"batch_1024\"\n",
    "config[\"batch\"]=1024\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e13b52-9b87-4072-9103-b8fd93f3de24",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"batch_2048\"\n",
    "config[\"batch\"]=2048\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5647414-6ba3-4b52-8424-aa00385add2d",
   "metadata": {},
   "source": [
    "# For barlow twins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7a540d2-a657-479e-853f-b6e6e0c31b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory C:\\Users\\isxzl\\OneDrive\\Code\\VICReg-BarlowTwins-Ablation-Study\\experiment\\experiment_checkpoints\\batch VS model\\barlow_batch_32 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                      | Params\n",
      "--------------------------------------------------------------\n",
      "0 | backbone        | Sequential                | 11.2 M\n",
      "1 | projection_head | BarlowTwinsProjectionHead | 9.4 M \n",
      "2 | criterion       | BarlowTwinsLoss           | 0     \n",
      "--------------------------------------------------------------\n",
      "20.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 M    Total params\n",
      "82.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                                                         | 0/98 [00:00<?, ?it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:359: UserWarning: `ModelCheckpoint(monitor='train_loss')` could not find the monitored key in the returned metrics: ['epoch', 'step']. HINT: Did you call `log('train_loss', value)` in the `LightningModule`?\n",
      "  warning_cache.warn(m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:37<00:00,  2.65it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:37<00:00,  2.65it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"barlow_batch_32\"\n",
    "config[\"batch\"]=32\n",
    "config[\"model\"]=\"BarlowTwins\"\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f02bb78-0942-408a-a950-3b605a091adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory C:\\Users\\isxzl\\OneDrive\\Code\\VICReg-BarlowTwins-Ablation-Study\\experiment\\experiment_checkpoints\\batch VS model\\barlow_batch_64 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                      | Params\n",
      "--------------------------------------------------------------\n",
      "0 | backbone        | Sequential                | 11.2 M\n",
      "1 | projection_head | BarlowTwinsProjectionHead | 9.4 M \n",
      "2 | criterion       | BarlowTwinsLoss           | 0     \n",
      "--------------------------------------------------------------\n",
      "20.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 M    Total params\n",
      "82.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:37<00:00,  2.64it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:37<00:00,  2.64it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"barlow_batch_64\"\n",
    "config[\"batch\"]=64\n",
    "config[\"model\"]=\"BarlowTwins\"\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "117e095b-109b-4bde-8e6a-836d3077a1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory C:\\Users\\isxzl\\OneDrive\\Code\\VICReg-BarlowTwins-Ablation-Study\\experiment\\experiment_checkpoints\\batch VS model\\barlow_batch_128 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                      | Params\n",
      "--------------------------------------------------------------\n",
      "0 | backbone        | Sequential                | 11.2 M\n",
      "1 | projection_head | BarlowTwinsProjectionHead | 9.4 M \n",
      "2 | criterion       | BarlowTwinsLoss           | 0     \n",
      "--------------------------------------------------------------\n",
      "20.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 M    Total params\n",
      "82.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:37<00:00,  2.60it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:37<00:00,  2.60it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"barlow_batch_128\"\n",
    "config[\"batch\"]=128\n",
    "config[\"model\"]=\"BarlowTwins\"\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35022b4e-be87-45df-9c17-016a73977a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory C:\\Users\\isxzl\\OneDrive\\Code\\VICReg-BarlowTwins-Ablation-Study\\experiment\\experiment_checkpoints\\batch VS model\\barlow_batch_256 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                      | Params\n",
      "--------------------------------------------------------------\n",
      "0 | backbone        | Sequential                | 11.2 M\n",
      "1 | projection_head | BarlowTwinsProjectionHead | 9.4 M \n",
      "2 | criterion       | BarlowTwinsLoss           | 0     \n",
      "--------------------------------------------------------------\n",
      "20.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 M    Total params\n",
      "82.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:41<00:00,  2.34it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:41<00:00,  2.34it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"barlow_batch_256\"\n",
    "config[\"batch\"]=256\n",
    "config[\"model\"]=\"BarlowTwins\"\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "574808a7-dd11-4647-80c0-e95cb4951c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory C:\\Users\\isxzl\\OneDrive\\Code\\VICReg-BarlowTwins-Ablation-Study\\experiment\\experiment_checkpoints\\batch VS model\\barlow_batch_512 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                      | Params\n",
      "--------------------------------------------------------------\n",
      "0 | backbone        | Sequential                | 11.2 M\n",
      "1 | projection_head | BarlowTwinsProjectionHead | 9.4 M \n",
      "2 | criterion       | BarlowTwinsLoss           | 0     \n",
      "--------------------------------------------------------------\n",
      "20.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 M    Total params\n",
      "82.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:42<00:00,  2.30it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:42<00:00,  2.30it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"barlow_batch_512\"\n",
    "config[\"batch\"]=512\n",
    "config[\"model\"]=\"BarlowTwins\"\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d0ba9bf-909f-47dc-b6b8-4f131d28197b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory C:\\Users\\isxzl\\OneDrive\\Code\\VICReg-BarlowTwins-Ablation-Study\\experiment\\experiment_checkpoints\\batch VS model\\barlow_batch_1024 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                      | Params\n",
      "--------------------------------------------------------------\n",
      "0 | backbone        | Sequential                | 11.2 M\n",
      "1 | projection_head | BarlowTwinsProjectionHead | 9.4 M \n",
      "2 | criterion       | BarlowTwinsLoss           | 0     \n",
      "--------------------------------------------------------------\n",
      "20.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 M    Total params\n",
      "82.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:41<00:00,  2.36it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:41<00:00,  2.36it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"barlow_batch_1024\"\n",
    "config[\"batch\"]=1024\n",
    "config[\"model\"]=\"BarlowTwins\"\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e68f81e9-719b-405f-82a1-7a1b0cef6f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory C:\\Users\\isxzl\\OneDrive\\Code\\VICReg-BarlowTwins-Ablation-Study\\experiment\\experiment_checkpoints\\batch VS model\\barlow_batch_2048 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                      | Params\n",
      "--------------------------------------------------------------\n",
      "0 | backbone        | Sequential                | 11.2 M\n",
      "1 | projection_head | BarlowTwinsProjectionHead | 9.4 M \n",
      "2 | criterion       | BarlowTwinsLoss           | 0     \n",
      "--------------------------------------------------------------\n",
      "20.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 M    Total params\n",
      "82.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:42<00:00,  2.29it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 98/98 [00:42<00:00,  2.29it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# MAKE YOUR OWN CONFIG\n",
    "config=global_config\n",
    "# Fill the config\n",
    "SSL_augmentation=global_SSL_augmentation\n",
    "config[\"name\"]=\"barlow_batch_2048\"\n",
    "config[\"batch\"]=2048\n",
    "config[\"model\"]=\"BarlowTwins\"\n",
    "\n",
    "# THIS IS THE CODE TO LOAD DATASET\n",
    "pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "# THIS IS THE CODE TO LOAD MODEL\n",
    "pmodel=pipe_model(config=config)\n",
    "\n",
    "# Use this if you want to START a train\n",
    "trainer=Trainer(config, model_mode=\"start\")\n",
    "trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "# Use this if you want to CONTINUE to train\n",
    "#trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "#trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50686839-6777-4c26-b7f6-02b871ac184a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca362de1-b68b-45c8-94f6-853afff878aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the training and testing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:04<00:00, 1733.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:04<00:00, 1819.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2001/2001 [00:01<00:00, 1654.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2001/2001 [00:01<00:00, 1783.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [01:30<00:00, 12.92s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_augmentation = {\n",
    "    'RandomResizedCrop': {'size': (global_config[\"input_size\"], global_config[\"input_size\"])},\n",
    "    'ToTensor': {},\n",
    "    'Normalize': {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]}\n",
    "}\n",
    "collate =pipe_collate(address=\"experiment_checkpoints/batch VS model/\", reg=\"batch_[0-9]+\")\n",
    "\n",
    "pdata = PipeDataset(input_dir=global_config[\"path_to_test_cifar10\"],\n",
    "    augmentation=dict2transformer(test_augmentation,view=1))\n",
    "\n",
    "aaa=eval_linear(pdata, models=collate, device=global_config[\"device\"], split=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff8f9096-89ab-4926-8c60-cca73920c337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collating the models' (evaluating) information to experiment_checkpoints/batch VS model/barlow_batch_[0-9]+.csv\n",
      "Load the training and testing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:04<00:00, 1742.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:04<00:00, 1786.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2001/2001 [00:01<00:00, 1676.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2001/2001 [00:01<00:00, 1986.36it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_augmentation = {\n",
    "    'RandomResizedCrop': {'size': (global_config[\"input_size\"], global_config[\"input_size\"])},\n",
    "    'ToTensor': {},\n",
    "    'Normalize': {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]}\n",
    "}\n",
    "collate =pipe_collate(address=\"experiment_checkpoints/batch VS model/\", reg=\"barlow_batch_[0-9]+\")\n",
    "\n",
    "pdata = PipeDataset(input_dir=global_config[\"path_to_test_cifar10\"],\n",
    "    augmentation=dict2transformer(test_augmentation,view=1))\n",
    "\n",
    "aaa=eval_linear(pdata, models=collate, device=global_config[\"device\"], split=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed89fa6-f9b9-4af6-8531-da9c2729d020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6201ac8-2e92-4f99-864d-52e9af99310c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
