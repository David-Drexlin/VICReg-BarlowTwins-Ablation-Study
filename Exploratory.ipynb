{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e48d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "from view_transform import ViewTransform\n",
    "from LARS import LARS\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb1838",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a9a44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO\\n- try with pretrained weights for resnet18\\n-->> It might be interesting investigate the efficiency frontier between max_batch and views \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TODO\n",
    "- try with pretrained weights for resnet18\n",
    "-->> It might be interesting investigate the efficiency frontier between max_batch and views \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "528447a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nExperiment: Change number of Views from 2 to 16 and record loss after 100 epochs\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Experiment: Change number of Views from 2 to 16 and record loss after 100 epochs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ede9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "warmup_steps = 10 \n",
    "epochs = 100 # Original set to 1000 \n",
    "output_enc = 1000\n",
    "dim = 8192\n",
    "num_views = 2\n",
    "\n",
    "num_workers = 4\n",
    "device = 'cpu' # or 'cuda' for faster training\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "# VicREG\n",
    "base_lr_ = 0.2\n",
    "learning_rate = batch_size/256 * base_lr_ \n",
    "weight_decay = 1e-6\n",
    "\n",
    "# BarlowTwins\n",
    "# learning_rate = base_lr * batch_size / 256\n",
    "# weight_decay = 1.5*1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79dd934",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e54b6deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "#trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)  \n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)  \n",
    "trainset.transform = ViewTransform(num_views)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "#linear_trainset = trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=linear_transform)  \n",
    "#linear_trainset = trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=linear_transform)  \n",
    "#linear_trainloader = torch.utils.data.DataLoader(linear_trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=linear_transform)  \n",
    "#testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=linear_transform)  \n",
    "#testset_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09abaec",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f25e24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = torchvision.models.resnet18()\n",
    "# encoder.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "def projector():\n",
    "    proj_layers = []\n",
    "\n",
    "    proj_layers.append(torch.nn.Linear(output_enc, dim))\n",
    "    proj_layers.append(torch.nn.ReLU(dim))\n",
    "    proj_layers.append(torch.nn.BatchNorm1d(dim))\n",
    "\n",
    "    proj_layers.append(torch.nn.Linear(dim, dim))\n",
    "    proj_layers.append(torch.nn.ReLU(dim))\n",
    "    proj_layers.append(torch.nn.BatchNorm1d(dim))\n",
    "    \n",
    "    proj_layers.append(torch.nn.Linear(dim, dim, bias=False))\n",
    "    \n",
    "    return torch.nn.Sequential(*proj_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8a5c7",
   "metadata": {},
   "source": [
    "## VicREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f33d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VicReg Paper - with modifications\n",
    "def VIC_Reg(Z):\n",
    "    \n",
    "    N = Z[0].shape[0]\n",
    "    D = Z[0].shape[1]\n",
    "\n",
    "    mu = 25\n",
    "    la = 25\n",
    "    nu = 1 \n",
    "    \n",
    "    sim_loss = 0\n",
    "    std_loss = 0\n",
    "    cov_loss = 0\n",
    "\n",
    "    for i in range(len(Z)): \n",
    "        for j in range(i+1, len(Z)): \n",
    "            sim_loss += F.mse_loss(Z[i], Z[j])\n",
    "\n",
    "    for zi in Z: \n",
    "        std_zi = torch.sqrt(zi.var(dim=0) + 1e-04)\n",
    "        std_loss += torch.mean(torch.relu(1 - std_zi)) \n",
    "    \n",
    "    for zi in Z: \n",
    "        zi = zi - zi.mean(dim=0)\n",
    "        cov_zi = (zi.T @ zi) / (N - 1)\n",
    "        cov_zi = cov_zi[~torch.eye(cov_zi.shape[0], dtype=bool)]\n",
    "        cov_loss += cov_zi.pow_(2).sum() / D\n",
    "\n",
    "    sim_loss /= 2*len(Z)\n",
    "    std_loss /= len(Z)\n",
    "    cov_loss /= len(Z)\n",
    "\n",
    "    loss = la * sim_loss + mu * std_loss + nu * cov_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e95f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
    "\n",
    "def adjust_learning_rate(optimizer, loader, step):\n",
    "    max_steps = epochs * len(loader)\n",
    "    warmup_steps = 10 * len(loader)\n",
    "    base_lr = base_lr_ * batch_size / 256\n",
    "    if step < warmup_steps:\n",
    "        lr = base_lr * step / warmup_steps\n",
    "    else:\n",
    "        step -= warmup_steps\n",
    "        max_steps -= warmup_steps\n",
    "        q = 0.5 * (1 + math.cos(math.pi * step / max_steps))\n",
    "        end_lr = base_lr * 0.001\n",
    "        lr = base_lr * q + end_lr * (1 - q)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ccb0d4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6b4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainset, offset): \n",
    "\n",
    "    encoder = torchvision.models.resnet18() # also try with pretrained=true\n",
    "    encoder.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    rpoj = projector()\n",
    "    model = torch.nn.Sequential(encoder, rpoj)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = LARS(model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay) \n",
    "\n",
    "        \n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    logging.basicConfig(filename='logs/example.log', filemode='w', level=logging.INFO)\n",
    "    starttime = time.time()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        losses = []\n",
    "        for step, (X, _) in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "            \n",
    "            lr = adjust_learning_rate(optimizer, trainloader, step)  \n",
    "            \n",
    "            if step % offset == 0: \n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            Z = []\n",
    "            for xi in X: \n",
    "                xi = xi.to(device)\n",
    "                Z.append(model(xi))\n",
    "                \n",
    "            loss = VIC_Reg(Z)\n",
    "            logging.info('%s ,Epoch: %d, Step: %d, Loss: %d, Elapsed: %d, lr: %d', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())), i, step, loss, starttime-time.time(), lr)\n",
    "            \n",
    "            if step % offset == 0: \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.detach().item())\n",
    "\n",
    "\n",
    "        print(f\"Epoch: {i}, loss: {np.mean(losses)}\")\n",
    "        #DL 1 Homework 1 \n",
    "\n",
    "        torch.save(encoder.state_dict(), f'models/VicReg/model_{batch_size}_epoch_{i}.pt')\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c08dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "step = 1 \n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        encoder_vicreg = train(trainloader, step)\n",
    "        break  #  successful break out of the loop\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e):\n",
    "            print(\"Out of memory error occurred. Reducing batch size and retrying...\")\n",
    "            # Reduce batch size & Conversly increase step size\n",
    "            batch_size //= 2\n",
    "            step = step * 2\n",
    "\n",
    "            trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "        else:\n",
    "            raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
