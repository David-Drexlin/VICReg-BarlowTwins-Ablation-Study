{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e48d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "from view_transform import ViewTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb1838",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a9a44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO\\n- We use a learning rate warm-up period of 10 epochs, after which we reduce the learning rate by a factor of 1000 using a co- sine decay schedule \\n- LARS Optimizer there are implementations on github etc. \\n- TOP-5 Acc \\n- encoder = torchvision.models.resnet18() # also try with pretrained=true\\n\\n-->> It might be interesting investigate the efficency frontier between max_batch and num_positives \\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TODO\n",
    "- We use a learning rate warm-up period of 10 epochs, after which we reduce the learning rate by a factor of 1000 using a co- sine decay schedule \n",
    "- LARS Optimizer there are implementations on github etc. \n",
    "- TOP-5 Acc \n",
    "- encoder = torchvision.models.resnet18() # also try with pretrained=true\n",
    "\n",
    "-->> It might be interesting investigate the efficency frontier between max_batch and num_positives \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "epochs = 1 # Original set to 1000 \n",
    "dim = 1000 # depends on specific encoder architecture ie. modifications of basic, as-is resnet18\n",
    "num_positives = 2\n",
    "\n",
    "max_batch = 64\n",
    "batch_size = max_batch / num_positives \n",
    "num_workers = 4\n",
    "device = 'cpu' # or 'cuda' for faster training\n",
    "\n",
    "# VicREG\n",
    "base_lr = 0.2\n",
    "learning_rate = batch_size/256 * base_lr \n",
    "weight_decay = 1e-6\n",
    "\n",
    "# BarlowTwins\n",
    "# learning_rate = base_lr * batch_size / 256\n",
    "# weight_decay = 1.5*1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79dd934",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "445121ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    "        ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e54b6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "#trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())  \n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())  \n",
    "trainset.transform = ViewTransform(num_positives)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "#linear_trainset = trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=linear_transform)  \n",
    "linear_trainset = trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=linear_transform)  \n",
    "linear_trainloader = torch.utils.data.DataLoader(linear_trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=linear_transform)  \n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=linear_transform)  \n",
    "testset_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09abaec",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f25e24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = torchvision.models.resnet18()\n",
    "\n",
    "def projector():\n",
    "    proj_layers = []\n",
    "\n",
    "    for i in range(2):\n",
    "        proj_layers.append(torch.nn.Linear(dim, dim))\n",
    "        proj_layers.append(torch.nn.ReLU(dim))\n",
    "        proj_layers.append(torch.nn.BatchNorm1d(dim))\n",
    "    \n",
    "    return torch.nn.Sequential(*proj_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8a5c7",
   "metadata": {},
   "source": [
    "## VicREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0f33d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VicReg Paper - with modifications\n",
    "def VIC_Reg(Z):\n",
    "    \n",
    "    N = Z[0].shape[0]\n",
    "    D = Z[0].shape[1]\n",
    "\n",
    "    mu = 25 # as per VIC-Reg Paper -- Subject to change\n",
    "    la = 25 # \"   \"\n",
    "    nu = 1 #  \"   \"\n",
    "    \n",
    "    # invariance loss\n",
    "    sim_loss = 0\n",
    "    std_loss = 0\n",
    "    cov_loss = 0\n",
    "\n",
    "    for i in range(len(Z)): \n",
    "        for j in range(i+1, len(Z)): \n",
    "            sim_loss += F.mse_loss(Z[i], Z[j])\n",
    "    \n",
    "    for zi in Z: \n",
    "        std_zi = torch.sqrt(zi.var(dim=0) + 1e-04)\n",
    "        std_loss += torch.mean(torch.relu(1 - std_zi)) \n",
    "    \n",
    "    for zi in Z: \n",
    "        zi = zi - zi.mean(dim=0)\n",
    "        cov_zi = (zi.T @ zi) / (N - 1)\n",
    "        cov_zi = cov_zi[~torch.eye(cov_zi.shape[0], dtype=bool)]\n",
    "        cov_loss += cov_zi.pow_(2).sum() / D\n",
    "\n",
    "\n",
    "    # variance loss\n",
    "\n",
    "    #    st_loss = torch.mean(torch.relu(1 - torch.stack([torch.sqrt(zi.var(dim=0) + 1e-04) for zi in Z])))\n",
    "    #    cov_loss = torch.stack([(zi - zi.mean(dim=0)).T @ (zi - zi.mean(dim=0)) for zi in Z])\n",
    "    #    cov_loss = torch.sum(cov_loss[~torch.eye(cov_loss.shape[0], dtype=bool)]) / (D * (N - 1))\n",
    "    # \n",
    "\n",
    "    loss = la * sim_loss + mu * std_loss + nu * cov_loss\n",
    "    \n",
    "    return loss/len(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000d35eb",
   "metadata": {},
   "source": [
    "## Barlow Twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0eb0850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barlow Twins Paper - with modifications\n",
    "\n",
    "def barlow_twins(Z):\n",
    "    la = 0.005 # I am not entirely conviced la < 1  is sensible? \n",
    "    \n",
    "    #input is [batch_size, 1000]\n",
    "    #conv1d requires 3 dimensions, target CC is DxD i.e. 1000x1000\n",
    "\n",
    "    N = Z[0].shape[0]\n",
    "    D = Z[0].shape[1]\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    for i in range(len(Z)): \n",
    "        for j in range(len(Z)): \n",
    "            zi = Z[i] - Z[i].mean(dim=0)\n",
    "            zj = Z[j] - Z[j].mean(dim=0)\n",
    "\n",
    "            c = torch.matmul(zi.T, zj)\n",
    "            c_diff = (c - torch.eye(D)).pow(2)\n",
    "            \n",
    "            off_diags = (torch.ones(c_diff.shape).fill_diagonal_(0))*la\n",
    "            c_diff = c_diff*off_diags\n",
    "\n",
    "            loss += c_diff.sum()\n",
    "    \n",
    "    return loss / len(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ccb0d4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce6b4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainset, loss_mode = \"VicReg\"): \n",
    "    \n",
    "    mode = loss_mode ==  \"VicReg\"\n",
    "\n",
    "    encoder = torchvision.models.resnet18() # also try with pretrained=true\n",
    "    encoder.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    rpoj = projector()\n",
    "    model = torch.nn.Sequential(encoder, rpoj)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay) # TODO LARS\n",
    "\n",
    "    for i in range(epochs):\n",
    "        losses = []\n",
    "        for X, _ in tqdm(trainloader):\n",
    "            Z = []\n",
    "            for xi in X: \n",
    "                xi = xi.to(device)\n",
    "                Z.append(model(xi))\n",
    "                \n",
    "            if mode: \n",
    "                loss = VIC_Reg(Z)\n",
    "            else:\n",
    "                loss = barlow_twins(Z)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.detach().item())\n",
    "\n",
    "\n",
    "        print(f\"Epoch: {i}, loss: {np.mean(losses)}\")\n",
    "        #DL 1 Homework 1 \n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        if mode:\n",
    "            os.makedirs('models/VicReg', exist_ok=True)\n",
    "            torch.save(encoder.state_dict(), f'models/VicReg/model_{batch_size}_epoch_{i}.pt')\n",
    "        else:\n",
    "            os.makedirs('models/BarlowTwins', exist_ok=True)\n",
    "            torch.save(encoder.state_dict(), f'models/BarlowTwins/model_{batch_size}_epoch_{i}.pt')\n",
    "    \n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5de703bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1000, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [4, 4] at index 1 does not match the shape of the indexed tensor [4, 1000, 1000] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoder_vicreg \u001b[39m=\u001b[39m train(trainloader, loss_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mVicReg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[40], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainset, loss_mode)\u001b[0m\n\u001b[1;32m     20\u001b[0m     Z\u001b[39m.\u001b[39mappend(model(xi))\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m mode: \n\u001b[0;32m---> 23\u001b[0m     loss \u001b[39m=\u001b[39m VIC_Reg(Z)\n\u001b[1;32m     24\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     loss \u001b[39m=\u001b[39m barlow_twins(Z)\n",
      "Cell \u001b[0;32mIn[38], line 25\u001b[0m, in \u001b[0;36mVIC_Reg\u001b[0;34m(Z)\u001b[0m\n\u001b[1;32m     23\u001b[0m cov_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([(zi \u001b[39m-\u001b[39m zi\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m (zi \u001b[39m-\u001b[39m zi\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)) \u001b[39mfor\u001b[39;00m zi \u001b[39min\u001b[39;00m Z])\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(cov_loss\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 25\u001b[0m cov_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(cov_loss[\u001b[39m~\u001b[39;49mtorch\u001b[39m.\u001b[39;49meye(cov_loss\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], dtype\u001b[39m=\u001b[39;49m\u001b[39mbool\u001b[39;49m)]) \u001b[39m/\u001b[39m (D \u001b[39m*\u001b[39m (N \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m     28\u001b[0m \u001b[39m# variance loss\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# for zi in Z: \u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m#    std_zi = torch.sqrt(zi.var(dim=0) + 1e-04)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m#    cov_zi = cov_zi[~torch.eye(cov_zi.shape[0], dtype=bool)]\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m#    cov_loss += cov_zi.pow_(2).sum() / D\u001b[39;00m\n\u001b[1;32m     39\u001b[0m loss \u001b[39m=\u001b[39m la \u001b[39m*\u001b[39m sim_loss \u001b[39m+\u001b[39m mu \u001b[39m*\u001b[39m std_loss \u001b[39m+\u001b[39m nu \u001b[39m*\u001b[39m cov_loss\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [4, 4] at index 1 does not match the shape of the indexed tensor [4, 1000, 1000] at index 1"
     ]
    }
   ],
   "source": [
    "encoder_vicreg = train(trainloader, loss_mode=\"VicReg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6720257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/938 [01:06<31:18,  2.07s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoder_barlow \u001b[39m=\u001b[39m train(trainloader)\n",
      "Cell \u001b[0;32mIn[47], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainset, loss_mode)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     loss \u001b[39m=\u001b[39m barlow_twins(Z)\n\u001b[0;32m---> 27\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     28\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     29\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder_barlow = train(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99644a1e",
   "metadata": {},
   "source": [
    "## Linear Head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vicreg.eval()\n",
    "encoder_barlow.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path duplicate - keep for now as convenience loader\n",
    "def load_models(path=\"models/VicReg/model_16_epoch_0.pt\"):\n",
    "    encoder = torchvision.models.resnet18()\n",
    "    saved = torch.load(path)\n",
    "    encoder.load_state_dict(saved)\n",
    "    return encoder\n",
    "\n",
    "def linear_train(path=\"models/VicReg/model_16_epoch_0.pt\"):\n",
    "    # I dont understand how the guys from the vicreg paper combinded \n",
    "    # this LinearSVC and pytorch, to my understanding indicated\n",
    "    # by the fact that they use optimiser (but I am no expert, by any means) ^^\n",
    "    # clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    \n",
    "    encoder = load_models(path)\n",
    "    encoder.eval()\n",
    "\n",
    "    linear_classifier = torch.nn.Linear(dim, num_classes)\n",
    "    linear_classifier.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(linear_classifier.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        losses = []\n",
    "        for x, y in tqdm(linear_trainloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            latent_space = encoder(x)\n",
    "            output = linear_classifier(latent_space)\n",
    "            \n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.detach().item())\n",
    "\n",
    "    \n",
    "    print(f\"Epoch: {i}, loss: {np.mean(losses)}\")\n",
    "    os.makedirs('models/LC', exist_ok=True)\n",
    "    torch.save(encoder.state_dict(), f'models/LC/model_{batch_size}_epoch_{i}.pt')\n",
    "\n",
    "    \n",
    "    return linear_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca46dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(head):\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for x,y in tqdm(testset_loader):\n",
    "        head.eval()\n",
    "        model = torch.nn.Sequential(load_models(), head)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(x)\n",
    "        \n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # Update evaluation metrics\n",
    "        total_samples += y.size(0)\n",
    "        total_correct += (predicted_labels == y).sum().item()\n",
    "\n",
    "        return total_correct / total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784a78c",
   "metadata": {},
   "source": [
    "\n",
    "Linear classification. We follow standard protocols Misra & Maaten (2020); Caron et al. (2020); Zbontar et al. (2021) and train linear models on top of the frozen representations. For VOC07 Everingham et al. (2010), we train a linear SVM with LIBLINEAR Fan et al. (2008). The images are center cropped and resized to 224 × 224, and the C values are computed with cross-validation. For Places205 Zhou et al. (2014) we use SGD with a learning rate of 0.003, a weight decay of 0.0001, a momentum of 0.9 and a batch size of 256, for 28 epochs. The learning rate is divided by 10 at epochs 4, 8 and 12. For Inaturalist2018 Horn et al. (2018), we use SGD with a learning rate of 0.005, a weight decay of 0.0001, a momentum of 0.9 and a batch size of 256, for 84 epochs. The learning rate is divided by 10 at epochs 24, 48 and 72."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f1132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_train(\"models/BarlowTwins/model_16_epoch_0.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
