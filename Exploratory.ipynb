{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e48d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "from view_transform import ViewTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb1838",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO\n",
    "- We use a learning rate warm-up period of 10 epochs, after which we reduce the learning rate by a factor of 1000 using a co- sine decay schedule \n",
    "- LARS Optimizer there are implementations on github etc. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "epochs = 1 # Original set to 1000 \n",
    "dim = 1000 # depends on specific encoder architecture ie. modifications of basic, as-is ResNet50\n",
    "\n",
    "batch_size = 16 \n",
    "num_workers = 6\n",
    "device = 'cpu' # or 'cuda' for faster training\n",
    "\n",
    "# VicREG\n",
    "base_lr = 0.2\n",
    "learning_rate = batch_size/256 * base_lr #  for barlow twins \n",
    "weight_decay = 1e-6\n",
    "\n",
    "# BarlowTwins\n",
    "# learning_rate = base_lr * batch_size / 256\n",
    "# weight_decay = 1.5*1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79dd934",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445121ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    "        ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())  \n",
    "trainset.transform = ViewTransform()\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "linear_trainset = trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=linear_transform)  \n",
    "linear_trainloader = torch.utils.data.DataLoader(linear_trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=linear_transform)  \n",
    "testnset_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09abaec",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = torchvision.models.resnet50()\n",
    "\n",
    "def projector():\n",
    "    proj_layers = []\n",
    "\n",
    "    for i in range(4):\n",
    "        proj_layers.append(torch.nn.Linear(dim, dim))\n",
    "        proj_layers.append(torch.nn.ReLU(dim))\n",
    "        proj_layers.append(torch.nn.BatchNorm1d(dim))\n",
    "    \n",
    "    return torch.nn.Sequential(*proj_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8a5c7",
   "metadata": {},
   "source": [
    "## VicREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f33d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VicReg Paper - with modifications\n",
    "def VIC_Reg(z1, z2):\n",
    "    \n",
    "    N = z1.shape[0]\n",
    "    D = z1.shape[1]\n",
    "\n",
    "    mu = 25 # as per VIC-Reg Paper -- Subject to change\n",
    "    la = 25 # \"   \"\n",
    "    nu = 1 #  \"   \"\n",
    "    \n",
    "    # invariance loss\n",
    "    sim_loss = F.mse_loss(z1, z2)\n",
    "    \n",
    "    # variance loss\n",
    "    std_z_a = torch.sqrt(z1.var(dim=0) + 1e-04)\n",
    "    std_z_b = torch.sqrt(z2.var(dim=0) + 1e-04)\n",
    "    std_loss = torch.mean(torch.relu(1 - std_z_a)) + torch.mean(torch.relu(1 - std_z_b))\n",
    "    \n",
    "    # covariance loss\n",
    "    z1 = z1 - z1.mean(dim=0)\n",
    "    z2 = z2 - z2.mean(dim=0)\n",
    "    \n",
    "    cov_z_a = (z1.T @ z1) / (N - 1)\n",
    "    cov_z_b = (z2.T @ z2) / (N - 1)\n",
    "\n",
    "    cov_z_a = cov_z_a[~torch.eye(cov_z_a.shape[0], dtype=bool)] # Off diags\n",
    "    cov_z_b = cov_z_b[~torch.eye(cov_z_b.shape[0], dtype=bool)] # \" \"\n",
    "\n",
    "    cov_loss = cov_z_a.pow_(2).sum() / D + cov_z_b.pow_(2).sum() / D\n",
    "    loss = la * sim_loss + mu * std_loss + nu * cov_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000d35eb",
   "metadata": {},
   "source": [
    "## Barlow Twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb0850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barlow Twins Paper - with modifications\n",
    "\n",
    "def barlow_twins(z1, z2):\n",
    "    N = z1.shape[0]\n",
    "    D = z1.shape[1]\n",
    "    \n",
    "    z1_norm = (z1 - z1.mean(0)) / z1.std(0) # NxD\n",
    "    z2_norm = (z2 - z2.mean(0)) / z2.std(0) # NxD\n",
    "\n",
    "    print(z1_norm.shape)\n",
    "    \n",
    "    if(z1_norm.shape[0]==2048):\n",
    "        z1_norm = z1_norm.permute(0, 2, 1)  # (2048, 1, x)\n",
    "        z2_norm = z2_norm.permute(0, 2, 1)  # (2048, 1, x)\n",
    "\n",
    "    c = F.conv1d(z1_norm, z2_norm)\n",
    "    \n",
    "    # loss\n",
    "    c_diff = (c - torch.eye(D)).pow(2) # DxD #multiplyoff-diagonalelemsofc_diffbylambda off_diagonal(c_diff).mul_(lambda)\n",
    "    loss = c_diff.sum()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ccb0d4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainset, loss_mode = \"VicReg\"): \n",
    "    \n",
    "    mode = loss_mode ==  \"VicReg\"\n",
    "\n",
    "    encoder = torchvision.models.resnet50()\n",
    "    rpoj = projector()\n",
    "    model = torch.nn.Sequential(encoder, rpoj)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay) # TODO LARS\n",
    "\n",
    "    for i in range(epochs):\n",
    "        losses = []\n",
    "        for (x1, x2), _ in tqdm(trainloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x1, x2 = x1.to(device), x2.to(device)\n",
    "            z1, z2 = model(x1), model(x2)\n",
    "            \n",
    "            if mode: \n",
    "                loss = VIC_Reg(z1, z2)\n",
    "            else:\n",
    "                loss = barlow_twins(z1, z2)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.detach().item())\n",
    "\n",
    "\n",
    "        print(f\"Epoch: {i}, loss: {np.mean(losses)}\")\n",
    "        #DL 1 Homework 1 \n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        torch.save(encoder.state_dict(), f'models/model_epoch_{i}.pt')\n",
    "    \n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5de703bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vicreg = train(trainloader, loss_mode=\"VicReg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_barlow = train(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99644a1e",
   "metadata": {},
   "source": [
    "## Linear Head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vicreg.eval()\n",
    "encoder_barlow.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_train(encoder):\n",
    "    \n",
    "    clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model = torch.nn.Sequential(encoder, clf)\n",
    "    model = model.to(device)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        losses = []\n",
    "        for x, y in tqdm(linear_trainloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "\n",
    "\n",
    "            (latent_space, y)\n",
    "            loss = \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.detach().item())\n",
    "\n",
    "    \n",
    "    print(f\"Epoch: {i}, loss: {np.mean(losses)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca46dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_train(encoder_vicreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f75ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_train(encoder_barlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Linear classification. We follow standard protocols Misra & Maaten (2020); Caron et al. (2020); Zbontar et al. (2021) and train linear models on top of the frozen representations. For VOC07 Everingham et al. (2010), we train a linear SVM with LIBLINEAR Fan et al. (2008). The images are center cropped and resized to 224 × 224, and the C values are computed with cross-validation. For Places205 Zhou et al. (2014) we use SGD with a learning rate of 0.003, a weight decay of 0.0001, a momentum of 0.9 and a batch size of 256, for 28 epochs. The learning rate is divided by 10 at epochs 4, 8 and 12. For Inaturalist2018 Horn et al. (2018), we use SGD with a learning rate of 0.005, a weight decay of 0.0001, a momentum of 0.9 and a batch size of 256, for 84 epochs. The learning rate is divided by 10 at epochs 24, 48 and 72."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
