{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e48d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "from view_transform import ViewTransform\n",
    "from LARS import LARS\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb1838",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO\n",
    "- try with pretrained weights for resnet18\n",
    "-->> It might be interesting investigate the efficiency frontier between max_batch and views \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "warmup_steps = 10 \n",
    "epochs = 5 # Original set to 1000 \n",
    "output_enc = 1000\n",
    "dim = 8192\n",
    "num_views = 2\n",
    "offset = 1 \n",
    "\n",
    "num_workers = 4\n",
    "device = 'cuda' # or 'cuda' for faster training\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "# VicREG\n",
    "base_lr_ = 0.2\n",
    "learning_rate = batch_size/256 * base_lr_ \n",
    "weight_decay = 1e-6\n",
    "\n",
    "# BarlowTwins\n",
    "# learning_rate = base_lr * batch_size / 256\n",
    "# weight_decay = 1.5*1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79dd934",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "#trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)  \n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)  \n",
    "trainset.transform = ViewTransform(num_views)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "#linear_trainset = trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=linear_transform)  \n",
    "#linear_trainset = trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=linear_transform)  \n",
    "#linear_trainloader = torch.utils.data.DataLoader(linear_trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=linear_transform)  \n",
    "#testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=linear_transform)  \n",
    "#testset_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09abaec",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = torchvision.models.resnet18()\n",
    "# encoder.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "def projector():\n",
    "    proj_layers = []\n",
    "\n",
    "    proj_layers.append(torch.nn.Linear(output_enc, dim))\n",
    "    proj_layers.append(torch.nn.ReLU(dim))\n",
    "    proj_layers.append(torch.nn.BatchNorm1d(dim))\n",
    "\n",
    "    proj_layers.append(torch.nn.Linear(dim, dim))\n",
    "    proj_layers.append(torch.nn.ReLU(dim))\n",
    "    proj_layers.append(torch.nn.BatchNorm1d(dim))\n",
    "    \n",
    "    proj_layers.append(torch.nn.Linear(dim, dim, bias=False))\n",
    "    \n",
    "    return torch.nn.Sequential(*proj_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8a5c7",
   "metadata": {},
   "source": [
    "## VicREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f33d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VicReg Paper - with modifications\n",
    "def VIC_Reg(Z):\n",
    "    \n",
    "    N = Z[0].shape[0]\n",
    "    D = Z[0].shape[1]\n",
    "\n",
    "    mu = 25\n",
    "    la = 25\n",
    "    nu = 1 \n",
    "    \n",
    "    sim_loss = 0\n",
    "    std_loss = 0\n",
    "    cov_loss = 0\n",
    "\n",
    "    for i in range(len(Z)): \n",
    "        for j in range(i+1, len(Z)): \n",
    "            sim_loss += F.mse_loss(Z[i], Z[j])\n",
    "\n",
    "    for zi in Z: \n",
    "        std_zi = torch.sqrt(zi.var(dim=0) + 1e-04)\n",
    "        std_loss += torch.mean(torch.relu(1 - std_zi)) \n",
    "    \n",
    "    for zi in Z: \n",
    "        zi = zi - zi.mean(dim=0)\n",
    "        cov_zi = (zi.T @ zi) / (N - 1)\n",
    "        cov_zi = cov_zi[~torch.eye(cov_zi.shape[0], dtype=bool)]\n",
    "        cov_loss += cov_zi.pow_(2).sum() / D\n",
    "\n",
    "    sim_loss /= (len(Z) * (len(Z)-1)) / 2\n",
    "    std_loss /= len(Z)\n",
    "    cov_loss /= len(Z)\n",
    "\n",
    "    loss = la * sim_loss + mu * std_loss + nu * cov_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e95f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
    "\n",
    "def adjust_learning_rate(optimizer, loader, step):\n",
    "    max_steps = epochs * len(loader)\n",
    "    warmup_steps = 10 * len(loader)\n",
    "    base_lr = base_lr_ * batch_size / 256\n",
    "    if step < warmup_steps:\n",
    "        lr = base_lr * step / warmup_steps\n",
    "    else:\n",
    "        step -= warmup_steps\n",
    "        max_steps -= warmup_steps\n",
    "        q = 0.5 * (1 + math.cos(math.pi * step / max_steps))\n",
    "        end_lr = base_lr * 0.001\n",
    "        lr = base_lr * q + end_lr * (1 - q)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ccb0d4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainset, offset): \n",
    "\n",
    "    encoder = torchvision.models.resnet18() # also try with pretrained=true\n",
    "    encoder.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    rpoj = projector()\n",
    "    model = torch.nn.Sequential(encoder, rpoj)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = LARS(model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay) \n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    logging.basicConfig(filename=f'logs/b:{batch_size}_v:{num_views}.log', filemode='w', level=logging.INFO)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        losses = []\n",
    "        for step, (X, _) in tqdm(enumerate(trainloader), total=epochs*len(trainloader)):\n",
    "            \n",
    "            if step % offset == 0: \n",
    "                lr = adjust_learning_rate(optimizer, trainloader, step)  \n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            Z = []\n",
    "            for xi in X: \n",
    "                xi = xi.to(device)\n",
    "                Z.append(model(xi))\n",
    "                \n",
    "            loss = VIC_Reg(Z)\n",
    "            logging.info('%s ,Epoch: %d, Step: %d, Loss: %.3f, Elapsed: %d, views: %d', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())), i, step, loss, starttime-time.time(), num_views)\n",
    "            \n",
    "            if step % offset == 0: \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.detach().item())\n",
    "\n",
    "\n",
    "        print(f\"Epoch: {i}, loss: {np.mean(losses)}\")\n",
    "        #DL 1 Homework 1 \n",
    "\n",
    "        torch.save(encoder.state_dict(), f'models/VicReg/model_{num_views}_{batch_size}_epoch_{i}.pt')\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff997348",
   "metadata": {},
   "source": [
    "encoder_vicreg = train(trainloader, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c08dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(2,17)):\n",
    "    num_views = i \n",
    "    at_limit = False\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)  \n",
    "    trainset.transform = ViewTransform(num_views)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            if(at_limit):\n",
    "                batch_size //= 2\n",
    "                offset = offset * 2\n",
    "                trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "                \n",
    "            encoder_vicreg = train(trainloader, offset)\n",
    "            break  #  successful break out of the loop\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                print(\"Out of memory error occurred. Reducing batch size and retrying...\")\n",
    "                # Reduce batch size & Conversly increase step size\n",
    "                batch_size //= 2\n",
    "                offset = offset * 2\n",
    "                at_limit = True\n",
    "\n",
    "                trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "            else:\n",
    "                raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
