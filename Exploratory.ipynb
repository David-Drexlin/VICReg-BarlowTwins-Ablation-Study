{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e48d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "from view_transform import ViewTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb1838",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a9a44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO\\n- We use a learning rate warm-up period of 10 epochs, after which we reduce the learning rate by a factor of 1000 using a co- sine decay schedule \\n- LARS Optimizer there are implementations on github etc. \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TODO\n",
    "- We use a learning rate warm-up period of 10 epochs, after which we reduce the learning rate by a factor of 1000 using a co- sine decay schedule \n",
    "- LARS Optimizer there are implementations on github etc. \n",
    "- TOP-5 Acc \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ede9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "epochs = 1 # Original set to 1000 \n",
    "dim = 1000 # depends on specific encoder architecture ie. modifications of basic, as-is ResNet50\n",
    "\n",
    "batch_size = 16 \n",
    "num_workers = 4\n",
    "device = 'cpu' # or 'cuda' for faster training\n",
    "\n",
    "# VicREG\n",
    "base_lr = 0.2\n",
    "learning_rate = batch_size/256 * base_lr #  for barlow twins \n",
    "weight_decay = 1e-6\n",
    "\n",
    "# BarlowTwins\n",
    "# learning_rate = base_lr * batch_size / 256\n",
    "# weight_decay = 1.5*1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79dd934",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445121ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    "        ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e54b6deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())  \n",
    "trainset.transform = ViewTransform()\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "linear_trainset = trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=linear_transform)  \n",
    "linear_trainloader = torch.utils.data.DataLoader(linear_trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=linear_transform)  \n",
    "testset_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09abaec",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f25e24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = torchvision.models.resnet50()\n",
    "\n",
    "def projector():\n",
    "    proj_layers = []\n",
    "\n",
    "    for i in range(4):\n",
    "        proj_layers.append(torch.nn.Linear(dim, dim))\n",
    "        proj_layers.append(torch.nn.ReLU(dim))\n",
    "        proj_layers.append(torch.nn.BatchNorm1d(dim))\n",
    "    \n",
    "    return torch.nn.Sequential(*proj_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8a5c7",
   "metadata": {},
   "source": [
    "## VicREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f33d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VicReg Paper - with modifications\n",
    "def VIC_Reg(z1, z2):\n",
    "    \n",
    "    N = z1.shape[0]\n",
    "    D = z1.shape[1]\n",
    "\n",
    "    mu = 25 # as per VIC-Reg Paper -- Subject to change\n",
    "    la = 25 # \"   \"\n",
    "    nu = 1 #  \"   \"\n",
    "    \n",
    "    # invariance loss\n",
    "    sim_loss = F.mse_loss(z1, z2)\n",
    "    \n",
    "    # variance loss\n",
    "    std_z_a = torch.sqrt(z1.var(dim=0) + 1e-04)\n",
    "    std_z_b = torch.sqrt(z2.var(dim=0) + 1e-04)\n",
    "    std_loss = torch.mean(torch.relu(1 - std_z_a)) + torch.mean(torch.relu(1 - std_z_b))\n",
    "    \n",
    "    # covariance loss\n",
    "    z1 = z1 - z1.mean(dim=0)\n",
    "    z2 = z2 - z2.mean(dim=0)\n",
    "    \n",
    "    cov_z_a = (z1.T @ z1) / (N - 1)\n",
    "    cov_z_b = (z2.T @ z2) / (N - 1)\n",
    "\n",
    "    cov_z_a = cov_z_a[~torch.eye(cov_z_a.shape[0], dtype=bool)] # Off diags\n",
    "    cov_z_b = cov_z_b[~torch.eye(cov_z_b.shape[0], dtype=bool)] # \" \"\n",
    "\n",
    "    cov_loss = cov_z_a.pow_(2).sum() / D + cov_z_b.pow_(2).sum() / D\n",
    "    loss = la * sim_loss + mu * std_loss + nu * cov_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000d35eb",
   "metadata": {},
   "source": [
    "## Barlow Twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb0850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barlow Twins Paper - with modifications\n",
    "\n",
    "def barlow_twins(z1, z2):\n",
    "    la = 0.005 # I am not entirely conviced la < 1  is sensible? \n",
    "\n",
    "    N = z1.shape[0]\n",
    "    D = z1.shape[1]\n",
    "    \n",
    "    z1_norm = (z1 - z1.mean(0)) / z1.std(0) # NxD\n",
    "    z2_norm = (z2 - z2.mean(0)) / z2.std(0) # NxD\n",
    "\n",
    "    #input is [batch_size, 1000]\n",
    "    #conv1d requires 3 dimensions, target CC is DxD i.e. 1000x1000\n",
    "\n",
    "    z1_norm = z1_norm[:, None , :]  \n",
    "    z2_norm = z2_norm[:, None , :] \n",
    "\n",
    "    c = F.conv1d(z1_norm.T, z2_norm.T)\n",
    "    \n",
    "    # loss\n",
    "    c_diff = (c - torch.eye(D)).pow(2) # DxD #multiplyoff-diagonalelemsofc_diffbylambda \n",
    "    off_diags = (torch.ones(c_diff.shape, dtype=torch.int).fill_diagonal_(0))*la\n",
    "    c_diff = c_diff*off_diags\n",
    "    loss = c_diff.sum()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ccb0d4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce6b4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainset, loss_mode = \"VicReg\"): \n",
    "    \n",
    "    mode = loss_mode ==  \"VicReg\"\n",
    "\n",
    "    encoder = torchvision.models.resnet50()\n",
    "    rpoj = projector()\n",
    "    model = torch.nn.Sequential(encoder, rpoj)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay) # TODO LARS\n",
    "\n",
    "    for i in range(epochs):\n",
    "        losses = []\n",
    "        for (x1, x2), _ in tqdm(trainloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x1, x2 = x1.to(device), x2.to(device)\n",
    "            z1, z2 = model(x1), model(x2)\n",
    "\n",
    "            if mode: \n",
    "                loss = VIC_Reg(z1, z2)\n",
    "            else:\n",
    "                loss = barlow_twins(z1, z2)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.detach().item())\n",
    "\n",
    "\n",
    "        print(f\"Epoch: {i}, loss: {np.mean(losses)}\")\n",
    "        #DL 1 Homework 1 \n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        if mode:\n",
    "            os.makedirs('VicReg', exist_ok=True)\n",
    "            torch.save(encoder.state_dict(), f'models/VicReg/model_{batch_size}_epoch_{i}.pt')\n",
    "        else:\n",
    "            os.makedirs('BarlowTwins', exist_ok=True)\n",
    "            torch.save(encoder.state_dict(), f'models/BarlowTwins/model_{batch_size}_epoch_{i}.pt')\n",
    "\n",
    "    \n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5de703bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [44:56<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 39.53907440063477\n"
     ]
    }
   ],
   "source": [
    "encoder_vicreg = train(trainloader, loss_mode=\"VicReg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6720257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [45:47<00:00,  1.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 39.946143161621094\n"
     ]
    }
   ],
   "source": [
    "encoder_barlow = train(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99644a1e",
   "metadata": {},
   "source": [
    "## Linear Head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e940b3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_vicreg.eval()\n",
    "encoder_barlow.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31ab661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path duplicate - keep for now as convenience loader\n",
    "def load_models(path=\"models/VicReg/model_16_epoch_0.pt\"):\n",
    "    encoder = torchvision.models.resnet50()\n",
    "    saved = torch.load(path)\n",
    "    encoder.load_state_dict(saved)\n",
    "    return encoder\n",
    "\n",
    "def linear_train(path=\"models/VicReg/model_16_epoch_0.pt\"):\n",
    "    # I dont understand how the guys from the vicreg paper combinded \n",
    "    # this LinearSVC and pytorch, to my understanding indicated\n",
    "    # by the fact that they use optimiser (but I am no expert, by any means) ^^\n",
    "    # clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    \n",
    "    encoder = load_models(path)\n",
    "    encoder.eval()\n",
    "\n",
    "    linear_classifier = torch.nn.Linear(dim, num_classes)\n",
    "    linear_classifier.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(linear_classifier.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        losses = []\n",
    "        for x, y in tqdm(linear_trainloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            latent_space = encoder(x)\n",
    "            output = linear_classifier(latent_space)\n",
    "            \n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.detach().item())\n",
    "\n",
    "    \n",
    "    print(f\"Epoch: {i}, loss: {np.mean(losses)}\")\n",
    "    \n",
    "    return linear_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cca46dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1695/3125 [12:42<10:39,  2.23it/s] "
     ]
    }
   ],
   "source": [
    "model = linear_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(head):\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for x,y in tqdm(testset_loader):\n",
    "        model.eval()\n",
    "        model = torch.nn.Sequential(load_models, head)\n",
    "\n",
    "        with torch.no_grad:\n",
    "            outputs = model(x)\n",
    "        \n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Update evaluation metrics\n",
    "            total_samples += y.size(0)\n",
    "            total_correct += (predicted_labels == y).sum().item()\n",
    "\n",
    "        return total_correct / total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784a78c",
   "metadata": {},
   "source": [
    "\n",
    "Linear classification. We follow standard protocols Misra & Maaten (2020); Caron et al. (2020); Zbontar et al. (2021) and train linear models on top of the frozen representations. For VOC07 Everingham et al. (2010), we train a linear SVM with LIBLINEAR Fan et al. (2008). The images are center cropped and resized to 224 × 224, and the C values are computed with cross-validation. For Places205 Zhou et al. (2014) we use SGD with a learning rate of 0.003, a weight decay of 0.0001, a momentum of 0.9 and a batch size of 256, for 28 epochs. The learning rate is divided by 10 at epochs 4, 8 and 12. For Inaturalist2018 Horn et al. (2018), we use SGD with a learning rate of 0.005, a weight decay of 0.0001, a momentum of 0.9 and a batch size of 256, for 84 epochs. The learning rate is divided by 10 at epochs 24, 48 and 72."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f1132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_train(\"models/BarlowTwins/model_16_epoch_0.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
