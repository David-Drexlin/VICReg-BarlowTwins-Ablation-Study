{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c1b63f5-2b84-438d-803f-e996f8a346a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from lightly.data import LightlyDataset, SimCLRCollateFunction, collate\n",
    "from lightly.loss import NTXentLoss\n",
    "from lightly.models import ResNetGenerator\n",
    "from lightly.models.modules.heads import MoCoProjectionHead\n",
    "from lightly.models.utils import (\n",
    "    batch_shuffle,\n",
    "    batch_unshuffle,\n",
    "    deactivate_requires_grad,\n",
    "    update_momentum,\n",
    ")\n",
    "from lightly.models.modules.heads import SimSiamPredictionHead, SimSiamProjectionHead\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80f7d6f-f39f-4797-bf27-6ad5754aa592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    }
   ],
   "source": [
    "num_workers = 8\n",
    "batch_size = 512\n",
    "memory_bank_size = 4096\n",
    "seed = 1\n",
    "max_epochs = 1\n",
    "input_size=32\n",
    "pl.seed_everything(seed)\n",
    "path_to_train = \"../Datasets/cifar10/train/\"\n",
    "path_to_test = \"../Datasets/cifar10/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86bc2af-bd90-4801-bf78-c418e856b54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740f441-2fe0-42a1-9cf9-d7ec52082e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25212e21-6cb6-45ad-931d-0a132c628699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MoCo v2 uses SimCLR augmentations, additionally, disable blur\n",
    "collate_fn = SimCLRCollateFunction(\n",
    "    input_size=input_size,\n",
    "    gaussian_blur=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bff137f-e615-49b7-b4f4-7e0ebdba5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations typically used to train on cifar-10\n",
    "train_classifier_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.RandomCrop(input_size, padding=4),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=collate.imagenet_normalize[\"mean\"],\n",
    "            std=collate.imagenet_normalize[\"std\"],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# No additional augmentations for the test set\n",
    "test_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((input_size, input_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=collate.imagenet_normalize[\"mean\"],\n",
    "            std=collate.imagenet_normalize[\"std\"],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc1717d-8298-4dbc-9df4-a1536a122468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We use the moco augmentations for training moco\n",
    "dataset_train_simclr = LightlyDataset(input_dir=path_to_train)\n",
    "\n",
    "# Since we also train a linear classifier on the pre-trained moco model we\n",
    "# reuse the test augmentations here (MoCo augmentations are very strong and\n",
    "# usually reduce accuracy of models which are not used for contrastive learning.\n",
    "# Our linear layer will be trained using cross entropy loss and labels provided\n",
    "# by the dataset. Therefore we chose light augmentations.)\n",
    "dataset_train_classifier = LightlyDataset(\n",
    "    input_dir=path_to_train, transform=train_classifier_transforms\n",
    ")\n",
    "\n",
    "dataset_test = LightlyDataset(input_dir=path_to_test, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1ce14-17af-4496-bef5-7d86f0c7c140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7bedd94-3865-466c-a63e-364a845aae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train_simclr = torch.utils.data.DataLoader(\n",
    "    dataset_train_simclr,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "dataloader_train_classifier = torch.utils.data.DataLoader(\n",
    "    dataset_train_classifier,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f97eeea-e36e-4525-9869-01413b4150b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b0155-23f3-4b90-9ec0-d85354491f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66314f43-1227-4d38-b431-040d41201baf",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class SimSiam(nn.Module):\n",
    "    def __init__(self, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.projection_head = SimSiamProjectionHead(num_ftrs, proj_hidden_dim, out_dim)\n",
    "        self.prediction_head = SimSiamPredictionHead(out_dim, pred_hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get representations\n",
    "        f = self.backbone(x).flatten(start_dim=1)\n",
    "        # get projections\n",
    "        z = self.projection_head(f)\n",
    "        # get predictions\n",
    "        p = self.prediction_head(z)\n",
    "        # stop gradient\n",
    "        z = z.detach()\n",
    "        return z, p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63279c2c-6e09-4c6a-9ab3-a23b4c64693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of the embeddings\n",
    "num_ftrs = 512\n",
    "# dimension of the output of the prediction and projection heads\n",
    "out_dim = proj_hidden_dim = 512\n",
    "# the prediction head uses a bottleneck architecture\n",
    "pred_hidden_dim = 128\n",
    "\n",
    "model = SimSiam( num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f2181-d66e-40cc-a33a-81559ca7fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimSiam uses a symmetric negative cosine similarity loss\n",
    "criterion = NegativeCosineSimilarity()\n",
    "\n",
    "# scale the learning rate\n",
    "lr = 0.05 * batch_size / 256\n",
    "# use SGD with momentum and weight decay\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5e331-85d0-4266-a65d-4a9984ecfb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "avg_loss = 0.0\n",
    "avg_output_std = 0.0\n",
    "for e in range(max_epochs):\n",
    "    for (x0, x1), _, _ in dataloader_train_simclr:\n",
    "        # move images to the gpu\n",
    "        x0 = x0.to(device)\n",
    "        x1 = x1.to(device)\n",
    "\n",
    "        # run the model on both transforms of the images\n",
    "        # we get projections (z0 and z1) and\n",
    "        # predictions (p0 and p1) as output\n",
    "        z0, p0 = model(x0)\n",
    "        z1, p1 = model(x1)\n",
    "\n",
    "        # apply the symmetric negative cosine similarity\n",
    "        # and run backpropagation\n",
    "        loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate the per-dimension standard deviation of the outputs\n",
    "        # we can use this later to check whether the embeddings are collapsing\n",
    "        output = p0.detach()\n",
    "        output = torch.nn.functional.normalize(output, dim=1)\n",
    "\n",
    "        output_std = torch.std(output, 0)\n",
    "        output_std = output_std.mean()\n",
    "\n",
    "        # use moving averages to track the loss and standard deviation\n",
    "        w = 0.9\n",
    "        avg_loss = w * avg_loss + (1 - w) * loss.item()\n",
    "        avg_output_std = w * avg_output_std + (1 - w) * output_std.item()\n",
    "\n",
    "    # the level of collapse is large if the standard deviation of the l2\n",
    "    # normalized output is much smaller than 1 / sqrt(dim)\n",
    "    collapse_level = max(0.0, 1 - math.sqrt(out_dim) * avg_output_std)\n",
    "    # print intermediate results\n",
    "    print(\n",
    "        f\"[Epoch {e:3d}] \"\n",
    "        f\"Loss = {avg_loss:.2f} | \"\n",
    "        f\"Collapse Level: {collapse_level:.2f} / 1.00\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16b97e-7f2f-4c4b-b113-6cc5adc58d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Initialize features and labels as empty numpy arrays\n",
    "X_train = np.array([])\n",
    "y_train = np.array([])\n",
    "\n",
    "# Wrap your dataloader with tqdm for a progress bar\n",
    "for image, target, fname in tqdm(dataloader_train_classifier):\n",
    "    with torch.no_grad():\n",
    "        # Forward pass to extract features\n",
    "        # Note: You might need to modify this depending on the output of your SimCLR model\n",
    "        feature = model.backbone(image.to(device)).cpu().numpy().flatten()\n",
    "        target = target.cpu().numpy().flatten()\n",
    "\n",
    "        # If features and labels are empty, assign the first feature and label\n",
    "        # Else, stack the new feature and label as a new row\n",
    "\n",
    "        if X_train.size == 0 and y_train.size == 0:\n",
    "            X_train = feature\n",
    "            y_train = target\n",
    "        else:\n",
    "            X_train = np.vstack((X_train, feature))\n",
    "            y_train = np.hstack((y_train, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0505a9-aa04-4a1c-b8ea-b267c497a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM classifier\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "X_test_predicted = clf.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, X_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a45794-4abf-417e-94c1-4c924878d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8062611b-17f8-48c6-a37d-41eab5337a20",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m      8\u001b[0m fname_test\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, target, fname \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader_test\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     12\u001b[0m         feature \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbackbone(image\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tqdm\n",
    "# Initialize features and labels as empty numpy arrays\n",
    "X_test = np.array([])\n",
    "y_test = np.array([])\n",
    "fname_test=[]\n",
    "for image, target, fname in tqdm(dataloader_test):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        feature = model.backbone(image.to(device)).cpu().numpy().flatten()\n",
    "        target = target.cpu().numpy().flatten()\n",
    "\n",
    "    if X_test.size == 0 and y_test.size == 0:\n",
    "        X_test = feature\n",
    "        y_test = target\n",
    "    else:\n",
    "        X_test = np.vstack((X_test, feature))\n",
    "        y_test = np.hstack((y_test, target))\n",
    "    fname_test.append(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c030475b-c05e-4b32-a410-19b8e8251b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.04296100462656973\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict labels for test data\n",
    "X_test_predicted = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, X_test_predicted)\n",
    "\n",
    "print(f\"Model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbda431-5f7e-48dc-86e2-8e1f89997336",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpimg\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m random_indices \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[43mX_test\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m random_indices:\n\u001b[0;32m      8\u001b[0m     distances, indices \u001b[38;5;241m=\u001b[39m nbrs\u001b[38;5;241m.\u001b[39mkneighbors(X_test[idx]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "root_path = '../Datasets/cifar10/test/'\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "random_indices = random.sample(range(X_test.shape[0]), 2)\n",
    "for idx in random_indices:\n",
    "    distances, indices = nbrs.kneighbors(X_test[idx].reshape(1, -1))\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "    fig.suptitle('Nearest neighbors for: '+str(fname_test[idx][0]), fontsize=16)\n",
    "    example_label = y_test[idx]\n",
    "    \n",
    "    # Iterate over the neighbors\n",
    "    for i, index in enumerate(indices[0]):\n",
    "        image_path = root_path + fname_test[index][0]  # Extract the filename from the tuple and prepend the root path\n",
    "        img = mpimg.imread(image_path)\n",
    "        label = y_test[index]\n",
    "        \n",
    "        # Choose label color based on match with example\n",
    "        color = 'red' if label != example_label else 'black'\n",
    "        \n",
    "        # Plot image and label\n",
    "        axs[i//3, i%3].imshow(img)\n",
    "        axs[i//3, i%3].set_title('Label: '+str(label), color=color)\n",
    "        axs[i//3, i%3].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385e0fc-0022-4c82-a5ac-683dbb6a7be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
